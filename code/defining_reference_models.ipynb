{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "\n",
    "from models import AggregateLearner\n",
    "from utils import refSample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performanceP(true, f1, acc, n=1000, rs=42):\n",
    "    np.random.seed(rs)\n",
    "\n",
    "    f1_dist = np.array([f1_score(true, np.random.choice(2, len(true)))\n",
    "                        for _ in range(n)])\n",
    "    f1N = np.sum(f1_dist > f1)\n",
    "    f1p = 1.0 * f1N / n\n",
    "    print(\"F1: {0}/{1} (p = {2}; chance = {3})\".format(f1N, n, f1p, np.mean(f1_dist)))\n",
    "    \n",
    "    acc_dist = np.array([accuracy_score(true, np.random.choice(2, len(true)))\n",
    "                for _ in range(n)])\n",
    "    accN = np.sum(acc_dist > acc)\n",
    "    accp = 1.0 * accN / n\n",
    "    print(\"Acc: {0}/{1} (p = {2}; chance = {3})\".format(accN, n, accp, np.mean(acc_dist)))\n",
    "    return f1p, accp\n",
    "\n",
    "\n",
    "def logoffset(x): return np.log10(x+1)\n",
    "def passthrough(x): return x\n",
    "def rank(x): return sp.stats.rankdata(x, method='average', axis=1)\n",
    "def nonzerolocs(x, p=0.8): return np.where(np.percentile(x, (1-p)*100, axis=0) > 0)\n",
    "def prune(x, p=0.8, locs=None): return np.vstack(x[:, locs]) if locs else np.vstack(x[:, nonzerolocs(x, p)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "df = pd.read_hdf('../data/aggregation_connect+feature+demo_dset100x1x1x20.h5')\n",
    "\n",
    "# Create dummy classifier instance to determine prune locations\n",
    "target = \"age\"\n",
    "observation = \"simulation\"\n",
    "refstr = \"ref\"\n",
    "jack = 100\n",
    "rs = 41\n",
    "p=0.2\n",
    "\n",
    "clf = AggregateLearner(df, [], target_id=target, observation_id=observation,\n",
    "                       sample_id='subject', data_id='graph', refstr=refstr,\n",
    "                       cvfolds=5, oos=0.2, jack=jack, triu=True,\n",
    "                       random_seed=rs, verbose=False)\n",
    "\n",
    "X, y, g = clf._prep_data(clf.dat, clf.tar, clf.sam, refSample, index=clf.refloc)\n",
    "X_t, y_t, g_t = clf._prep_data(clf.dat_t, clf.tar_t, clf.sam_t, refSample, index=clf.refloc)\n",
    "\n",
    "locs = nonzerolocs(np.vstack([X, X_t]), p=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pre-processing components\n",
    "prn = ('prune', FunctionTransformer(prune, kw_args={'locs':locs}))\n",
    "log = ('log', FunctionTransformer(logoffset))\n",
    "rnk = ('rnk', FunctionTransformer(rank))\n",
    "passthrough = ('pass', FunctionTransformer(passthrough))\n",
    "\n",
    "# Create decomposition components\n",
    "pca = ('pca', PCA(n_components=20))\n",
    "lda = ('lda', LinearDiscriminantAnalysis())\n",
    "\n",
    "# Create classifier components\n",
    "svc = ('svc', SVC(class_weight=\"balanced\", probability=True, max_iter=1e5))\n",
    "lrc = ('lrc', LogisticRegression(class_weight=\"balanced\", solver='liblinear', max_iter=1e5, penalty='l2'))\n",
    "gnb = ('gnb', GaussianNB())\n",
    "gpc = ('gpc', GaussianProcessClassifier())\n",
    "knn = ('knn', KNeighborsClassifier(n_neighbors=10))\n",
    "rfc = ('rfc', RandomForestClassifier(class_weight=\"balanced\"))\n",
    "ada = ('ada', AdaBoostClassifier())\n",
    "clfs = [svc, gnb, gpc, knn, rfc, ada]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age :  FunctionTransformer(func=<function rank at 0x11949fc80>) -> PCA(n_components=20) -> LogisticRegression(class_weight='balanced', max_iter=100000.0,\n",
      "                   solver='liblinear')\n",
      "  aggregation       acc        f1   p_acc    p_f1  test_acc   test_f1  p_test_acc  p_test_f1  test_mean_acc  test_mean_f1  n_models\n",
      "0         ref  0.704167  0.781031  0.0424  0.0444      0.65  0.758621       0.061      0.045           0.68       0.77892         5\n",
      "F1: 41/1000 (p = 0.041; chance = 0.5729847496870505)\n",
      "Acc: 63/1000 (p = 0.063; chance = 0.5021)\n"
     ]
    }
   ],
   "source": [
    "target = \"age\"\n",
    "pipe = Pipeline([rnk, pca, lrc])\n",
    "\n",
    "clf = AggregateLearner(df, pipe, target_id=target, observation_id=observation,\n",
    "                       sample_id='subject', data_id='graph', refstr=refstr,\n",
    "                       cvfolds=5, oos=0.2, jack=jack, triu=True,\n",
    "                       random_seed=rs, verbose=False)\n",
    "\n",
    "_, y_t, _ = clf._prep_data(clf.dat_t, clf.tar_t, clf.sam_t, refSample, index=clf.refloc)\n",
    "\n",
    "print(target, \": \", \" -> \".join(str(p) for p in pipe))\n",
    "perf = clf.fit(aggregation=\"ref\")\n",
    "print(clf.performance_report().to_string())\n",
    "\n",
    "f1p, accp = performanceP(y_t, perf['f1'], perf['acc'], n=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex :  FunctionTransformer(func=<function logoffset at 0x11949fa60>) -> PCA(n_components=20) -> GaussianNB()\n",
      "  aggregation     acc        f1   p_acc    p_f1  test_acc   test_f1  p_test_acc  p_test_f1  test_mean_acc  test_mean_f1  n_models\n",
      "0         ref  0.6025  0.730364  0.1448  0.0806      0.65  0.774194       0.061      0.015           0.62      0.749677         5\n",
      "F1: 15/1000 (p = 0.015; chance = 0.5408287689913871)\n",
      "Acc: 48/1000 (p = 0.048; chance = 0.49679999999999996)\n"
     ]
    }
   ],
   "source": [
    "target = \"sex\"\n",
    "pipe = Pipeline([log, pca, gnb])\n",
    "\n",
    "clf = AggregateLearner(df, pipe, target_id=target, observation_id=observation,\n",
    "                       sample_id='subject', data_id='graph', refstr=refstr,\n",
    "                       cvfolds=5, oos=0.2, jack=jack, triu=True,\n",
    "                       random_seed=rs, verbose=False)\n",
    "\n",
    "_, y_t, _ = clf._prep_data(clf.dat_t, clf.tar_t, clf.sam_t, refSample, index=clf.refloc)\n",
    "\n",
    "print(target, \": \", \" -> \".join(str(p) for p in pipe))\n",
    "perf = clf.fit(aggregation=\"ref\")\n",
    "print(clf.performance_report().to_string())\n",
    "\n",
    "f1p, accp = performanceP(y_t, perf['f1'], perf['acc'], n=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bmi :  FunctionTransformer(func=<function logoffset at 0x11949fa60>) -> PCA(n_components=20) -> RandomForestClassifier(class_weight='balanced')\n",
      "  aggregation  acc        f1   p_acc    p_f1  test_acc   test_f1  p_test_acc  p_test_f1  test_mean_acc  test_mean_f1  n_models\n",
      "0         ref  0.6  0.620363  0.1972  0.2386       0.7  0.727273        0.02      0.017           0.62      0.627273         5\n",
      "F1: 17/1000 (p = 0.017; chance = 0.490177290194139)\n",
      "Acc: 23/1000 (p = 0.023; chance = 0.5075)\n"
     ]
    }
   ],
   "source": [
    "target = \"bmi\"\n",
    "pipe = Pipeline([log, pca, rfc])\n",
    "\n",
    "clf = AggregateLearner(df, pipe, target_id=target, observation_id=observation,\n",
    "                       sample_id='subject', data_id='graph', refstr=refstr,\n",
    "                       cvfolds=5, oos=0.2, jack=jack, triu=True,\n",
    "                       random_seed=rs, verbose=False)\n",
    "\n",
    "_, y_t, _ = clf._prep_data(clf.dat_t, clf.tar_t, clf.sam_t, refSample, index=clf.refloc)\n",
    "\n",
    "print(target, \": \", \" -> \".join(str(p) for p in pipe))\n",
    "perf = clf.fit(aggregation=\"ref\")\n",
    "print(clf.performance_report().to_string())\n",
    "\n",
    "f1p, accp = performanceP(y_t, perf['f1'], perf['acc'], n=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rel_vo2max :  FunctionTransformer(func=<function rank at 0x11949fc80>) -> PCA(n_components=20) -> SVC(class_weight='balanced', max_iter=100000.0, probability=True)\n",
      "  aggregation       acc        f1  p_acc    p_f1  test_acc  test_f1  p_test_acc  p_test_f1  test_mean_acc  test_mean_f1  n_models\n",
      "0         ref  0.540833  0.550364  0.313  0.3706      0.45     0.56       0.589      0.308           0.51      0.595222         5\n",
      "F1: 312/1000 (p = 0.312; chance = 0.4968675929171709)\n",
      "Acc: 630/1000 (p = 0.63; chance = 0.5071)\n"
     ]
    }
   ],
   "source": [
    "target = \"rel_vo2max\"\n",
    "pipe = Pipeline([rnk, pca, svc])\n",
    "\n",
    "clf = AggregateLearner(df, pipe, target_id=target, observation_id=observation,\n",
    "                       sample_id='subject', data_id='graph', refstr=refstr,\n",
    "                       cvfolds=5, oos=0.2, jack=jack, triu=True,\n",
    "                       random_seed=rs, verbose=False)\n",
    "\n",
    "_, y_t, _ = clf._prep_data(clf.dat_t, clf.tar_t, clf.sam_t, refSample, index=clf.refloc)\n",
    "\n",
    "print(target, \": \", \" -> \".join(str(p) for p in pipe))\n",
    "perf = clf.fit(aggregation=\"ref\")\n",
    "print(clf.performance_report().to_string())\n",
    "\n",
    "f1p, accp = performanceP(y_t, perf['f1'], perf['acc'], n=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"cholesterol\"\n",
    "\n",
    "for c in clfs:\n",
    "    pipe = Pipeline([prn, rnk, pca, gpc])\n",
    "\n",
    "    clf = AggregateLearner(df, pipe, target_id=target, observation_id=observation,\n",
    "                           sample_id='subject', data_id='graph', refstr=refstr,\n",
    "                           cvfolds=5, oos=0.2, jack=jack, triu=True,\n",
    "                           random_seed=rs, verbose=False)\n",
    "\n",
    "    _, y_t, _ = clf._prep_data(clf.dat_t, clf.tar_t, clf.sam_t, refSample, index=clf.refloc)\n",
    "\n",
    "    print(target, \": \", \" -> \".join(str(p) for p in pipe))\n",
    "    perf = clf.fit(aggregation=\"ref\")\n",
    "    print(clf.performance_report().to_string())\n",
    "\n",
    "    f1p, accp = performanceP(y_t, perf['f1'], perf['acc'], n=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agg",
   "language": "python",
   "name": "agg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
